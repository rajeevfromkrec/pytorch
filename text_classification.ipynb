{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOjxhN+x2p14W9tMWyhJwHo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajeevfromkrec/pytorch/blob/master/text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_edzxMcsfp0c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "04eae5c3-704f-4e87-de79-162acb0d7c06"
      },
      "source": [
        "!pip install torchtext==0.5\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/ef/54b8da26f37787f5c670ae2199329e7dccf195c060b25628d99e587dac51/torchtext-0.5.0-py3-none-any.whl (73kB)\n",
            "\r\u001b[K     |████▌                           | 10kB 13.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 20kB 1.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 30kB 1.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 40kB 1.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 51kB 1.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 61kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 71kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.5) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.5) (1.15.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.5) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.5) (1.18.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.5) (4.41.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.5) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.5) (3.0.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.5) (0.16.0)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed sentencepiece-0.1.91 torchtext-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMUu34KJ37OG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchtext.datasets import text_classification\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader,random_split\n",
        "import time\n",
        "import re\n",
        "from torchtext.data.utils import ngrams_iterator\n",
        "from torchtext.data.utils import get_tokenizer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0dZD8Jw1xHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NGRAMS=2\n",
        "batch_size=16"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4etNJ2095YR1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "640f35b3-6693-4ad7-e7c7-ea891b5824a9"
      },
      "source": [
        "!ls\n",
        "!mkdir data\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PRt5fHA5g1u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "728cab88-1184-471f-e11e-9b74c44e7c10"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP_E_xZY4mT4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "da82284c-e869-4065-d88b-be0ef5e707b0"
      },
      "source": [
        "train_dataset, test_dataset= text_classification.DATASETS['DBpedia'](root='./data',ngrams=NGRAMS,vocab=None)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dbpedia_csv.tar.gz: 68.3MB [00:01, 57.9MB/s]\n",
            "560000lines [00:53, 10563.09lines/s]\n",
            "560000lines [01:48, 5153.09lines/s]\n",
            "70000lines [00:12, 5452.68lines/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUrOtaHF5UB_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c8338cd8-7148-41c6-e3ad-2bcc5da24076"
      },
      "source": [
        "print( len(train_dataset))\n",
        "print(len(train_dataset.get_labels()))\n",
        "print( len(test_dataset))\n",
        "print(len(test_dataset.get_labels()))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "560000\n",
            "14\n",
            "70000\n",
            "14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad3QCFkZ635w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device =torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvNVpSTq6fNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class textSemntiment(nn.Module):\n",
        "  def __init__(self,vocab_size,embedding_dim,num_classes):\n",
        "    super().__init__()\n",
        "    self.embedding=nn.EmbeddingBag(vocab_size,embedding_dim,sparse=True)\n",
        "    self.fc=nn.Linear(embedding_dim,num_classes)\n",
        "    self.init_weights()\n",
        "\n",
        "  def init_weights(self):\n",
        "    initrange = 0.5\n",
        "    self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "    self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "    self.fc.bias.data.zero_()\n",
        "\n",
        "  def forward(self,text,offsets):\n",
        "    embedded=self.embedding(text,offsets)\n",
        "    out=self.fc(embedded)\n",
        "    return out\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2XDSaHYGFFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size=len(train_dataset.get_vocab())\n",
        "embedding_dim=32\n",
        "num_classes=len(train_dataset.get_labels())\n",
        "model=textSemntiment(vocab_size=vocab_size,embedding_dim=embedding_dim,num_classes=num_classes)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxxKLk-TGJXi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "59313442-beb7-469c-b40e-28d008edd255"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "textSemntiment(\n",
            "  (embedding): EmbeddingBag(6375026, 32, mode=mean)\n",
            "  (fc): Linear(in_features=32, out_features=14, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NLvsuKWdpt9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f5d20ce3-8c9b-4cf7-cc38-3a5edd47c940"
      },
      "source": [
        "text=train_dataset[55000][1]\n",
        "#print([0]+[len(text)])\n",
        "\n",
        "offset=[[0,67],[0,89],[0,43],[0,55]]\n",
        "print(offset)\n",
        "offsets=torch.tensor(offset[:-1]).cumsum(dim=0)\n",
        "print(offsets)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 67], [0, 89], [0, 43], [0, 55]]\n",
            "tensor([[  0,  67],\n",
            "        [  0, 156],\n",
            "        [  0, 199]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIxYksBbHgID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batch(batch):\n",
        "    label = torch.tensor([entry[0] for entry in batch])\n",
        "    text = [entry[1] for entry in batch]\n",
        "    offsets = [0] + [len(entry) for entry in text]\n",
        "    # torch.Tensor.cumsum returns the cumulative sum\n",
        "    # of elements in the dimension dim.\n",
        "    # torch.Tensor([1.0, 2.0, 3.0]).cumsum(dim=0)\n",
        "\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text = torch.cat(text)\n",
        "    return text, offsets, label"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIRQV79TR80s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqU8B8EfSGGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_func(sub_train_):\n",
        "  train_loss=0.0\n",
        "  train_acc=0.0\n",
        "  data=DataLoader(sub_train_,batch_size=batch_size, shuffle=True,collate_fn=generate_batch)\n",
        "\n",
        "  for i,(text,offset,cls) in enumerate(data):\n",
        "    optimizer.zero_grad()\n",
        "    text,offset,cls=text.to(device),offset.to(device),cls.to(device)\n",
        "    output=model(text,offset)\n",
        "    loss=criterion(output,cls)\n",
        "    train_loss  +=loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_acc +=(output.argmax(1)==cls).sum().item()\n",
        "  scheduler.step()\n",
        "  return train_loss/len(sub_train_),train_acc/len(sub_train_)\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgkRc46PWBF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(data_):\n",
        "    loss = 0\n",
        "    acc = 0\n",
        "    data = DataLoader(data_, batch_size=batch_size, collate_fn=generate_batch)\n",
        "    for text, offsets, cls in data:\n",
        "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(text, offsets)\n",
        "            loss = criterion(output, cls)\n",
        "            loss += loss.item()\n",
        "            acc += (output.argmax(1) == cls).sum().item()\n",
        "\n",
        "    return loss / len(data_), acc / len(data_)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmwqchsDXX0G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "1db13ca6-021d-42c4-ca36-ecdfe3c8f6fe"
      },
      "source": [
        "n_epochs=5\n",
        "min_valid_loss=float('inf')\n",
        "criterion=torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=4.0)\n",
        "scheduler=torch.optim.lr_scheduler.StepLR(optimizer,1,gamma=0.9)\n",
        "train_len = int(len(train_dataset) * 0.95)\n",
        "sub_train_, sub_valid_ = \\\n",
        "random_split(train_dataset, [train_len, len(train_dataset) - train_len])\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train_func(sub_train_)\n",
        "    valid_loss, valid_acc = test(sub_valid_)\n",
        "\n",
        "    secs = int(time.time() - start_time)\n",
        "    mins = secs / 60\n",
        "    secs = secs % 60\n",
        "\n",
        "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
        "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 2 minutes, 0 seconds\n",
            "\tLoss: 0.0025(train)\t|\tAcc: 98.9%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 99.1%(valid)\n",
            "Epoch: 2  | time in 2 minutes, 1 seconds\n",
            "\tLoss: 0.0012(train)\t|\tAcc: 99.5%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 99.1%(valid)\n",
            "Epoch: 3  | time in 2 minutes, 0 seconds\n",
            "\tLoss: 0.0006(train)\t|\tAcc: 99.8%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 99.1%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3_lJoZglNZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}