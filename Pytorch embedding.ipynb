{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled15.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPieOvWabEmrq5JcRISe+3n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajeevfromkrec/pytorch/blob/master/Pytorch%20embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow61rsIJQUg5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "bcff9f02-f6f6-411d-880a-13993831c2af"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-02 13:23:06--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-08-02 13:23:07--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-08-02 13:23:07--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.16MB/s    in 6m 29s  \n",
            "\n",
            "2020-08-02 13:29:37 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uapUt5YfTpb2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "367aa892-4229-4601-a7bf-a59952aa859a"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "glove.6B.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-kyL_RpTrsA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "1cefe7f5-2359-44ad-e3bd-e6175eab482c"
      },
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqNBcBYUQsw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embedding(file):\n",
        "  f=open(file,'r')\n",
        "  out=f.read()\n",
        "  embedding={}\n",
        "  for line in out:\n",
        "    out.split()\n",
        "    word=line[0]\n",
        "    print(word)\n",
        "    embedding[word]=npa.arary( [val for val in line[1:]])\n",
        "  f.close\n",
        "  return embedding"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78kEiEN0UGVA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "a7c9e228-71c5-4447-b43e-4d2cd399157d"
      },
      "source": [
        "get_embedding('glove.6B.300d.txt')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-542924567021>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'glove.6B.300d.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-0bc03bc5d56c>\u001b[0m in \u001b[0;36mget_embedding\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0membedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marary\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'npa' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arFNQn2pUhMo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e667a891-7b2a-451a-fd53-079b4ec070e5"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f3d81733168>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBRX_-AKb2Ok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_to_idx={'hello':0, 'world':1}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_alLbIoYb_-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeds=nn.Embedding(2,5)\n",
        "lookup_tensor= torch.tensor(word_to_idx['hello'], dtype=torch.long)\n",
        "hello_embeded= embeds(lookup_tensor)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dExkWbncZ64",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4e6dadda-b774-436c-bcfb-0f072a8bf326"
      },
      "source": [
        "print(hello_embeded)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0.6614,  0.2669,  0.0617,  0.6213, -0.4519],\n",
            "       grad_fn=<EmbeddingBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoQPGI-5ckhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDjXEHO3cvSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyqLwb6McvUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvBYh1TEcvYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context_szie=2\n",
        "embedding_dim=2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uttl7UDc8f0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
        "And dig deep trenches in thy beauty's field,\n",
        "Thy youth's proud livery so gazed on now,\n",
        "Will be a totter'd weed of small worth held:\n",
        "Then being asked, where all thy beauty lies,\n",
        "Where all the treasure of thy lusty days;\n",
        "To say, within thine own deep sunken eyes,\n",
        "Were an all-eating shame, and thriftless praise.\n",
        "How much more praise deserv'd thy beauty's use,\n",
        "If thou couldst answer 'This fair child of mine\n",
        "Shall sum my count, and make my old excuse,'\n",
        "Proving his beauty by succession thine!\n",
        "This were to be new made when thou art old,\n",
        "And see thy blood warm when thou feel'st it cold.\"\"\""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMSPbmYNc9ba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sentence=test_sentence.split()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cDcfvNSdBnA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "06689f16-2162-4aea-8c60-7d1884e7bb22"
      },
      "source": [
        "test_sentence[:10]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['When',\n",
              " 'forty',\n",
              " 'winters',\n",
              " 'shall',\n",
              " 'besiege',\n",
              " 'thy',\n",
              " 'brow,',\n",
              " 'And',\n",
              " 'dig',\n",
              " 'deep']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOTXgHxydGWE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8d08b9b-4fc5-410e-dd87-669ceb46cac1"
      },
      "source": [
        "trigrams = [([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n",
        "            for i in range(len(test_sentence) - 2)]\n",
        "# print the first 3, just so you can see what they look like\n",
        "print(trigrams[:3])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(['When', 'forty'], 'winters'), (['forty', 'winters'], 'shall'), (['winters', 'shall'], 'besiege')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9rPEUqAdi0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trigrams1= [ ([test_sentence[i], test_sentence[i+1]] , test_sentence[i+2]  )    for i in range(len(test_sentence)-2)]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxux3FLbeHw1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8f159a88-6227-4166-f90d-e5323d7325b9"
      },
      "source": [
        "trigrams1[:3]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['When', 'forty'], 'winters'),\n",
              " (['forty', 'winters'], 'shall'),\n",
              " (['winters', 'shall'], 'besiege')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abfyT5WseJSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab=set(test_sentence)\n",
        "word_to_idx={word:i for i,word in enumerate(vocab)}"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyPzWhWVepvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NgramLangageModel(nn.Module):\n",
        "  def __init__(self,vocab_size,embed_dim,context_size):\n",
        "    super().__init__()\n",
        "    self.embedding=nn.Embedding(vocab_size,embed_dim)\n",
        "    self.linear1=nn.Linear(embed_dim*context_size,128)\n",
        "    self.linear2=nn.Linear(128,vocab_size)\n",
        "\n",
        "\n",
        "  def forward(self, input):\n",
        "    embeds=self.embedding(input).view((1,-1))\n",
        "    out=self.linear1(embeds)\n",
        "    out=F.relu(out)\n",
        "    out=self.linear2(out)\n",
        "    log_probs=F.log_softmax(out)\n",
        "    return log_probs\n",
        "\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek6bUdVxevLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses=[]\n",
        "loss_function=nn.NLLLoss()\n",
        "model=NgramLangageModel(len(vocab),2,2)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nStgL7APh8c5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "489f30a8-1373-4d30-aa1d-556cade477a8"
      },
      "source": [
        "model"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NgramLangageModel(\n",
              "  (embedding): Embedding(97, 2)\n",
              "  (linear1): Linear(in_features=4, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=97, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKouleMYiNZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer=optim.SGD(model.parameters(),lr=.001)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fwuS23NirGu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "d329afed-8cba-48f3-d6f7-146d5e294099"
      },
      "source": [
        "for epoch in range(10):\n",
        "  total_loss=0\n",
        "  for context,targets in trigrams:\n",
        "    context_idx= torch.tensor([word_to_idx[w] for w in context],dtype=torch.long)\n",
        "    model.zero_grad()\n",
        "    log_probs=model(context_idx)\n",
        "    loss =loss_function(log_probs, torch.tensor([word_to_idx[targets]],dtype=torch.long))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss  +=loss.item()\n",
        "  losses.append(total_loss)\n",
        "\n",
        "print(losses)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[503.09426617622375, 500.6617097854614, 498.2647922039032, 495.9034540653229, 493.5766279697418, 491.2841022014618, 489.0254395008087, 486.8005027770996, 484.60845971107483, 482.44896841049194, 480.3221175670624]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0Iex542kr9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}